{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOP8u5ZbGSa34NI5eADMr2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PamePatzi/Sistema-inteligente-para-monitoreo-e-identificaci-n-temprana-de-melanoma/blob/main/MelanomaModelo1_ASAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SISTEMA INTELIGENTE PARA IDENTIFICACIÓN Y DIAGNOSTICO TEMPRANA DE MELANOMAS (Parte 1)"
      ],
      "metadata": {
        "id": "59xNVN1Zz6s2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta primera parte se presenta la creación de un modelo convolucional en el que se aplican 3 capas con las imagenes del dataset obtenido desde la página de Kaggle\n",
        "#Importacion de las depependencias"
      ],
      "metadata": {
        "id": "jL6x8eSHWk6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para empezar se cargan todas las librerías que se usaran en los codigos para su funcionamiento, incluyendo las que son de ayuda para la descarga del dataset."
      ],
      "metadata": {
        "id": "iBm4Tp6ja4h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "dM80uXWQOWMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mediante la credencial de kaggle y la API especifica del dataset extraido, se procede a descargarlo y descomprimirlo en su carpeta principal, además de eliminar el .zip que luego de descomprimirlo no usaremos."
      ],
      "metadata": {
        "id": "K5p7hvm6SSeA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc_6UCDOOox6"
      },
      "outputs": [],
      "source": [
        "# Se define las credentiales para acceder a Kaggle\n",
        "!mkdir ~/.kaggle # Crear el directorio .kaggle\n",
        "!touch ~/.kaggle/kaggle.json # Crear el archivo kaggle.json\n",
        "api_token = {\"username\":\"lexipatzi\",\"key\":\"af4d8478480353a66efb23e233482439\"} # Definir las credenciales de API de Kaggle\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file: # Guardando las credenciales\n",
        "    json.dump(api_token, file)\n",
        "!chmod 600 ~/.kaggle/kaggle.json # Establecer los permisos del archivo kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPg2ZQZTTx6Z",
        "outputId": "7e59432d-0b1b-4695-e25b-b8fd3e20b81c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading melanoma.zip to /content\n",
            "100% 5.24G/5.26G [00:57<00:00, 120MB/s]\n",
            "100% 5.26G/5.26G [00:57<00:00, 97.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d drscarlat/melanoma # Descargar el dataset desde Kaggle\n",
        "!unzip -qn '/content/melanoma.zip' -d /content/ > /dev/null # Descomprimiendo el dataset \n",
        "!rm /content/melanoma.zip # Eliminando el zip\n",
        "!rm -r dermmel/ # Eliminando el DERMMEL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Siguendo con el procedimiento se pretende realizar un aumento de datos haciendo uso de data augmentation, este procedimiento es extra, ya que se cuenta con un dataset suficiente para su entrenamiento, sin embargo se considera importante y relevante considerar un dataset con más imagenes para que el modelo sea lo más funcional posible"
      ],
      "metadata": {
        "id": "kiselFDlSRME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estas capas sólo están activas durante el entrenamiento, cuando se llama a Model.fitz\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.RandomRotation(0.2),\n",
        "])"
      ],
      "metadata": {
        "id": "VY5ThHl5O-l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparacion de los datos\n",
        "Se realiza un pre procesado de las imagenes para que estas se encuentren en el mismo formato y puedan ser analizadas de la misma manera. Con el siguente código las imagenes pasan por un rescalamiento, además que se agrega el target_size, para que el tamaño requerido sea de (224,224). "
      ],
      "metadata": {
        "id": "CfahyLPDSQ5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparación del conjunto de datos\n",
        "#datos train\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "train_dataset = train_datagen.flow_from_directory('/content/DermMel/train_sep', target_size=(224, 224), batch_size=10,class_mode='binary')\n",
        "#datos test\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
        "test_dataset = test_datagen.flow_from_directory('/content/DermMel/test',target_size=(224, 224),batch_size=10,class_mode='binary')\n",
        "#datos validación\n",
        "val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
        "validation_dataset = val_datagen.flow_from_directory('/content/DermMel/valid',target_size=(224, 224),batch_size=10,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJpdrsAcOTlW",
        "outputId": "14e1c327-4a9e-4ee9-df3c-84ca7d603d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10682 images belonging to 2 classes.\n",
            "Found 3561 images belonging to 2 classes.\n",
            "Found 3562 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZuDIySfsSQKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creación del modelo CNN\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(100, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilación del modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model.fit(train_dataset, epochs=10, validation_data=test_dataset)\n",
        "\n",
        "# Evaluación del modelo\n",
        "loss, accuracy = model.evaluate(validation_dataset)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "aO3-6J2ugduT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a666c0f-8e4a-4676-cb8f-6dfadfc01a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1069/1069 [==============================] - 1544s 1s/step - loss: 0.5875 - accuracy: 0.6546 - val_loss: 0.8871 - val_accuracy: 0.6698\n",
            "Epoch 2/10\n",
            "1069/1069 [==============================] - 1500s 1s/step - loss: 0.5203 - accuracy: 0.7243 - val_loss: 0.5223 - val_accuracy: 0.7214\n",
            "Epoch 3/10\n",
            "1069/1069 [==============================] - 1522s 1s/step - loss: 0.4477 - accuracy: 0.7881 - val_loss: 0.4160 - val_accuracy: 0.8141\n",
            "Epoch 4/10\n",
            "1069/1069 [==============================] - 1519s 1s/step - loss: 0.3987 - accuracy: 0.8191 - val_loss: 0.3895 - val_accuracy: 0.8166\n",
            "Epoch 5/10\n",
            "1069/1069 [==============================] - 1500s 1s/step - loss: 0.3843 - accuracy: 0.8233 - val_loss: 0.4166 - val_accuracy: 0.8116\n",
            "Epoch 6/10\n",
            "1069/1069 [==============================] - 1503s 1s/step - loss: 0.3593 - accuracy: 0.8400 - val_loss: 0.3640 - val_accuracy: 0.8312\n",
            "Epoch 7/10\n",
            "1069/1069 [==============================] - 1506s 1s/step - loss: 0.3425 - accuracy: 0.8474 - val_loss: 0.3582 - val_accuracy: 0.8411\n",
            "Epoch 8/10\n",
            "1069/1069 [==============================] - 1509s 1s/step - loss: 0.3378 - accuracy: 0.8533 - val_loss: 0.3416 - val_accuracy: 0.8512\n",
            "Epoch 9/10\n",
            "1069/1069 [==============================] - 1521s 1s/step - loss: 0.3199 - accuracy: 0.8607 - val_loss: 0.3349 - val_accuracy: 0.8531\n",
            "Epoch 10/10\n",
            "1069/1069 [==============================] - 1524s 1s/step - loss: 0.3096 - accuracy: 0.8671 - val_loss: 0.3261 - val_accuracy: 0.8559\n",
            "357/357 [==============================] - 130s 364ms/step - loss: 0.3059 - accuracy: 0.8711\n",
            "Loss: 0.3058653175830841\n",
            "Accuracy: 0.8711398243904114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1_z-9SGrSPU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/model1.h5')"
      ],
      "metadata": {
        "id": "hlCrZd1v1Jq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pruebas con Imagenes subidas"
      ],
      "metadata": {
        "id": "uw33P1WvSPE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Carga del modelo entrenado\n",
        "model = keras.models.load_model('/content/model1.h5')\n",
        "#imagen de prueba\n",
        "img_path = '/content/DermMel/valid/Melanoma/AUG_0_105.jpeg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "imga = image.img_to_array(img)\n",
        "imga = np.expand_dims(imga, axis=0)\n",
        "imga /= 255.0\n",
        "#predicción\n",
        "prediction = model.predict(imga)\n",
        "print(prediction)\n",
        "#class_idx = int(prediction[0][0])\n",
        "#print(\"predicción\",class_idx)\n",
        "if prediction < 0.5: #por las caracteristicas de nuestro modelo nos dara predicciones arriba de 0.5 o abajo de este\n",
        "    print(\"No melanoma\")\n",
        "else:\n",
        "    print(\"Melanoma\")"
      ],
      "metadata": {
        "id": "r3OAmNa5qtFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab970d72-f717-4937-d517-9abbff1d573d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 319ms/step\n",
            "[[0.59616774]]\n",
            "Melanoma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Envio de respuesta via Telegram"
      ],
      "metadata": {
        "id": "deFyiauqWEfD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln_PxgHl7g5R",
        "outputId": "7df2f527-7f43-48af-be8e-f138fb414813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-20.3-py3-none-any.whl (545 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m545.4/545.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx~=0.24.0 (from python-telegram-bot)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.24.0->python-telegram-bot) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx~=0.24.0->python-telegram-bot)\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx~=0.24.0->python-telegram-bot) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.24.0->python-telegram-bot) (1.3.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.18.0,>=0.15.0->httpx~=0.24.0->python-telegram-bot)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx~=0.24.0->python-telegram-bot) (3.6.2)\n",
            "Installing collected packages: h11, httpcore, httpx, python-telegram-bot\n",
            "Successfully installed h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 python-telegram-bot-20.3\n"
          ]
        }
      ],
      "source": [
        "!pip install python-telegram-bot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN = \"5858768507:AAFL8yBpPmfZAeJK826YxIfLtFZXzThpKJA\" # @param {type: \"string\"}\n",
        "CHAT_ID = \"5514441598\" # @param {type: \"string\"}"
      ],
      "metadata": {
        "id": "tlfNFjDxKJc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "def bot_send_text(bot_message):\n",
        "    \n",
        "    bot_token = TOKEN\n",
        "    bot_chatID = CHAT_ID\n",
        "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + bot_chatID + '&parse_mode=Markdown&text=' + bot_message\n",
        "\n",
        "    response = requests.get(send_text)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "G31dVCCwPYC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "#D = [1, 0, 1, 0] prediccion realizada\n",
        "if prediction < 0.5:\n",
        "    print(\"No melanoma\")\n",
        "else:\n",
        "    print(\"Melanoma\")\n",
        "# Obtener la fecha actual\n",
        "fecha_actual = datetime.date.today().strftime(\"%d-%m-%Y\")\n",
        "\n",
        "# Variables con los datos a llenar\n",
        "no_orden = \"\" # @param {type: \"string\"}\n",
        "nombre_paciente = \"\" # @param {type: \"string\"}\n",
        "edad_paciente = \"\" # @param {type: \"string\"}\n",
        "telefono = \"\" # @param {type: \"string\"}\n",
        "ci = \"\" # @param {type: \"string\"}\n",
        "x = \"\"\n",
        "if prediction >0.5:\n",
        "  x = \"Si posee un Melanoma\"\n",
        "else:\n",
        "  x = \"No posee un Melanoma\"\n",
        "# Generar el texto con los datos\n",
        "\n",
        "texto = f'''\\\n",
        "\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tPagina No. 01 \\\n",
        "\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tFecha: {fecha_actual}\\\n",
        "\\n================================================\\\n",
        "\\nNo Orden : {no_orden}\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tNo. ingreso : 010\\\n",
        "\\nPaciente : {nombre_paciente}\\tEdad\\t\\t\\t\\t\\t\\t\\t : {edad_paciente}\\\n",
        "\\nC.I.\\t\\t\\t\\t : {ci}\\t\\t\\t\\t\\t\\t\\tTelefono\\t\\t\\t : {telefono}\\\n",
        "\\nEl tiene el siguiente diagnostico: {x}\n",
        "'''\n",
        "\n",
        "# Enviar el texto al bot o imprimirlo\n",
        "print(texto)\n",
        "\n",
        "test_bot = bot_send_text(texto)"
      ],
      "metadata": {
        "id": "4huRkSmPPssv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9a9e9d-1127-43bc-9ef9-a29a3e11d48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melanoma\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tPagina No. 01 \n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tFecha: 06-06-2023\n",
            "================================================\n",
            "No Orden : \t\t\t\t\t\t\t\t\t\t\t\tNo. ingreso : 010\n",
            "Paciente : \tEdad\t\t\t\t\t\t\t : \n",
            "C.I.\t\t\t\t : \t\t\t\t\t\t\tTelefono\t\t\t : \n",
            "El tiene el siguiente diagnostico: Si posee un Melanoma\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prueba con cámara web\n"
      ],
      "metadata": {
        "id": "CC-M6NshSOBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "metadata": {
        "id": "XTczLwBKwBF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "def modelo(img):\n",
        "  # Load and compile the model\n",
        "  model = load_model('model1.h5')\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  # List of category names for the dataset CIFAR-10\n",
        "  category_names = ['melanoma', 'no_melanoma']\n",
        "  frame=img #load the image from the webcam\n",
        "  # Resize the frame to 32x32 pixels\n",
        "  frame = cv2.resize(frame, (224, 224))\n",
        "  frame_array = np.array(frame) #we transform it into an array\n",
        "  # Normalize the frame data\n",
        "  frame_array = frame_array.astype('float32') / 255\n",
        "  # Make predictions with the frame\n",
        "  predictions = model.predict(frame_array)\n",
        "  # Get the predicted label index\n",
        "  predicted_label_index = np.argmax(predictions[0])\n",
        "  # Get the predicted label value\n",
        "  predicted_label_value = predictions[0][predicted_label_index]\n",
        "  # Get the predicted category\n",
        "  predicted_category = category_names[predicted_label_index]\n",
        "  # Check if the predicted label value is greater than 0.65\n",
        "  if predicted_label_value > 0.65:\n",
        "      print(f\"{predicted_category}: {predicted_label_value}\")"
      ],
      "metadata": {
        "id": "rpT5HiKTVK82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "vQMF_rwowO0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prueba con Cámara web en tiempo real"
      ],
      "metadata": {
        "id": "bUnoV8tKVHIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "FEBcuuOjxKOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    modelo(img) #we send the image previously converted to the main function of this exercise Our result would be different predicctions made on real time."
      ],
      "metadata": {
        "id": "gwWe-xKdxsfK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}